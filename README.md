# Pyspark_practice
##Learning Objectives

###By completing this journey, I aim to:

-Understand Apache Spark fundamentals using PySpark

-Work confidently with Databricks notebooks and clusters

-Perform efficient data transformations using Spark DataFrames

-Apply Spark SQL, window functions, and joins

-Optimize Spark jobs for performance

-Build end-to-end ETL pipelines

-Use Delta Lake with Bronze, Silver, and Gold layers
